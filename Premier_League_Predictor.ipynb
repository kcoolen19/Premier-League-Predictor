{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Premier League Predictor Model**"
      ],
      "metadata": {
        "id": "MvreGAgbpyVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Import libraries** <br/>\n",
        "\n",
        "This section imports necessary libraries and modules to run the model:\n",
        "\n",
        "- `from sklearn.linear_model import LinearRegression`: This is the algorithm used for creating the predictive model. <br/>\n",
        "\n",
        "- `from sklearn.model_selection import train_test_split`: This function splits the dataset into training and testing subsets. <br/>\n",
        "\n",
        "- `from sklearn.preprocessing import StandardScaler`: This is used to scale the features so that they all have the same range and unit variance, ensuring the model's accuracy. <br/>\n",
        "\n",
        "- `from sklearn.metrics import mean_absolute_error`: This is used to calculate the model's error by comparing predicted values to the true values. <br/>\n",
        "\n",
        "- `import pandas as pd `: This is the library used for data manipulation, particularly for working with datasets in tabular form. <br/>\n",
        "\n",
        "- `from google.colab import files`: This is used to upload the dataset files to Google Colab."
      ],
      "metadata": {
        "id": "kUBGPzv1xI2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import pandas as pd\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "3BM9PTkxxUvE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Upload .csv Files** <br/>\n",
        "\n",
        "This code allows you to upload your .csv files containing Premier League data for each season. By running this code in Google Colab, you'll be prompted to upload the required files. Once uploaded, they can be used to load into pandas DataFrames for further analysis."
      ],
      "metadata": {
        "id": "_vSpLNZqFlVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "E6HUT6QOjegE",
        "outputId": "99a61c8e-8886-46cf-c092-0d540b76f388"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8340776b-6da4-4311-866a-1ba745bcb246\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8340776b-6da4-4311-866a-1ba745bcb246\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Premier_League_2016_2017.csv to Premier_League_2016_2017.csv\n",
            "Saving Premier_League_2017_2018.csv to Premier_League_2017_2018.csv\n",
            "Saving Premier_League_2018_2019.csv to Premier_League_2018_2019.csv\n",
            "Saving Premier_League_2019_2020.csv to Premier_League_2019_2020.csv\n",
            "Saving Premier_League_2020_2021.csv to Premier_League_2020_2021.csv\n",
            "Saving Premier_League_2021_2022.csv to Premier_League_2021_2022.csv\n",
            "Saving Premier_League_2022_2023.csv to Premier_League_2022_2023.csv\n",
            "Saving Premier_League_2023_2024.csv to Premier_League_2023_2024.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Loading Datasets** <br/>\n",
        "\n",
        "This section loads individual season datasets into pandas DataFrames. Each DataFrame represents the Premier League standings for a given season. After loading all datasets, they are combined into one larger DataFrame (df) using pd.concat(), which concatenates them into a single dataset. The fillna(0, inplace=True) ensures that any missing values in the dataset are filled with zero, which helps avoid issues during model training."
      ],
      "metadata": {
        "id": "yyPwa-3iGFxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "df_16_17 = pd.read_csv('Premier_League_2016_2017.csv')\n",
        "df_17_18 = pd.read_csv('Premier_League_2017_2018.csv')\n",
        "df_18_19 = pd.read_csv('Premier_League_2018_2019.csv')\n",
        "df_19_20 = pd.read_csv('Premier_League_2019_2020.csv')\n",
        "df_20_21 = pd.read_csv('Premier_League_2020_2021.csv')\n",
        "df_21_22 = pd.read_csv('Premier_League_2021_2022.csv')\n",
        "df_22_23 = pd.read_csv('Premier_League_2022_2023.csv')\n",
        "df_23_24 = pd.read_csv('Premier_League_2023_2024.csv')\n",
        "\n",
        "# Combine all datasets into one DataFrame\n",
        "df = pd.concat([df_16_17, df_17_18, df_18_19, df_19_20, df_20_21, df_21_22, df_22_23, df_23_24], ignore_index=True)\n",
        "df.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "eYM03qVYlFCb",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Feature defining**\n",
        "\n",
        " Here, the features (predictor variables) and target (the variable to predict) for the model are defined:\n",
        "\n",
        "- `features:`  A list of statistics from the dataset that will be used to predict the number of points a team will earn. <br/>\n",
        "- `Recent_Form: ` A new feature representing the rolling average of wins in the past 5 games. This captures a team's recent performance.\n",
        "- `Last_Year_Points: `This feature captures the points a team earned in the previous season, which may be a useful predictor of the team's performance in the current season.\n",
        "- The target variable `target` is defined as `'Points'`, which is the number of points each team earned in the league.\n",
        "- The list `teams_to_predict` contains the teams for which the model will predict the points for the upcoming season."
      ],
      "metadata": {
        "id": "JfxvusF9G3zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target for the model\n",
        "features = ['Win', 'Draw', 'Loss', 'Goals Scored', 'Goals Conceded',\n",
        "            'Goal Difference', 'Expected Goals Scored', 'Expected Goals Conceded',\n",
        "            'Expected Goal Difference']\n",
        "df['Recent_Form'] = df['Win'].rolling(window=5, min_periods=1).mean()\n",
        "features.append('Recent_Form')\n",
        "\n",
        "# Add 'Last_Year_Points' as a feature\n",
        "df['Last_Year_Points'] = df.groupby('Team')['Points'].shift(1)\n",
        "df.fillna({'Last_Year_Points': 0}, inplace=True)\n",
        "\n",
        "target = 'Points'\n",
        "\n",
        "# Teams to predict for the upcoming season\n",
        "teams_to_predict = ['Arsenal', 'Aston Villa', 'Bournemouth', 'Brentford', 'Brighton & Hove Albion', 'Chelsea',\n",
        "                    'Crystal Palace', 'Everton', 'Fulham', 'Ipswich', 'Leicester City', 'Liverpool', 'Manchester City',\n",
        "                    'Manchester United', 'Newcastle United', 'Nottingham Forest', 'Southampton', 'Tottenham',\n",
        "                    'West Ham', 'Wolves']"
      ],
      "metadata": {
        "id": "Wco8LVUCl5Zw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Training** <br/>\n",
        "This section splits the data into training and testing sets:\n",
        "\n",
        "- `df_train`: All rows of the dataset that do not correspond to the teams we want to predict.\n",
        "- `train_test_split()`: Splits the data into training and testing sets (70% for training, 30% for testing) using the features and target variables.\n",
        "\n",
        "Then, the features are scaled using `StandardScaler()`, which standardizes the data by removing the mean and scaling to unit variance. This is important for linear regression as it ensures that all features have the same scale.\n",
        "\n",
        "The `LinearRegression` model is initialized, and the model is trained on the scaled training data (`X_train` and `y_train`). After training, predictions are made on the test data (`X_test`), and the model’s performance is evaluated using `mean_absolute_error`, which calculates the average absolute difference between predicted and actual points."
      ],
      "metadata": {
        "id": "7APGpMZ4HnW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and test data\n",
        "df_train = df[~df['Team'].isin(teams_to_predict)]\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_train[features], df_train[target], test_size=0.3, random_state=42)\n",
        "\n",
        "# Scale features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model (ensure X_train and X_test are numpy arrays)\n",
        "# X_train and X_test should already be numpy arrays after scaling\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error: {mae:.2f}')"
      ],
      "metadata": {
        "id": "RJakJtqMEb3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a66a1f2-f871-42b2-ca28-e65aab826969"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error: 0.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Predictions** <br/>\n",
        "This section prepares the data to make predictions for the specified teams (`teams_to_predict`):\n",
        "\n",
        "- The data for the teams to predict is extracted from the dataset, and the features are averaged for each team using `groupby()` and `mean()`.\n",
        "- The features are then scaled using the same `StandardScaler` that was fitted on the training data, ensuring the prediction data is processed the same way.\n",
        "- The model predicts the points for each team, and the predictions are stored in the `Predicted_Points` column.\n",
        "- The teams are ranked by their predicted points in descending order, with the highest predicted points ranked first. This ranking is stored in the `Rank` column.\n",
        "- Finally, the results are printed, showing each team's rank, name, and predicted points for the upcoming season."
      ],
      "metadata": {
        "id": "OgfRcF54IYDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare prediction data for teams to predict\n",
        "df_predict = df[df['Team'].isin(teams_to_predict)].groupby('Team', as_index=False)[features].mean()\n",
        "\n",
        "# Scale prediction features\n",
        "df_predict[features] = scaler.transform(df_predict[features])\n",
        "\n",
        "# Convert to numpy arrays to avoid feature name warnings\n",
        "X_predict = df_predict[features].to_numpy()\n",
        "\n",
        "# Predict the points for the teams\n",
        "df_predict['Predicted_Points'] = model.predict(X_predict)\n",
        "\n",
        "# Sort by predicted points and rank the teams\n",
        "df_predict['Rank'] = df_predict['Predicted_Points'].rank(ascending=False, method='min')\n",
        "\n",
        "# Display the predictions sorted by predicted points\n",
        "results = df_predict[['Rank', 'Team', 'Predicted_Points']].sort_values(by='Rank')\n",
        "print(\"Predicted Points for the New Season:\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "i3bYX9NIEoae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e630c73-58aa-4076-e26b-a0e1e28a0496"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Points for the New Season:\n",
            "    Rank               Team  Predicted_Points\n",
            "10   1.0    Manchester City         89.500000\n",
            "9    2.0          Liverpool         82.125000\n",
            "0    3.0            Arsenal         70.875000\n",
            "14   4.0          Tottenham         69.000000\n",
            "11   5.0  Manchester United         68.625000\n",
            "4    5.0            Chelsea         68.625000\n",
            "1    7.0        Aston Villa         53.017501\n",
            "8    8.0     Leicester City         51.000000\n",
            "16   9.0             Wolves         49.833333\n",
            "6   10.0            Everton         49.375000\n",
            "3   11.0          Brentford         48.000000\n",
            "15  12.0           West Ham         47.857143\n",
            "5   13.0     Crystal Palace         45.375000\n",
            "2   14.0        Bournemouth         42.666667\n",
            "13  15.0        Southampton         40.142857\n",
            "7   16.0             Fulham         38.250000\n",
            "12  17.0  Nottingham Forest         37.000000\n"
          ]
        }
      ]
    }
  ]
}